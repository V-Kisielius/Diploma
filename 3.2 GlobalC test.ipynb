{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected devie is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import MyData\n",
    "from model import Net\n",
    "from config import device\n",
    "from helper import downscale_map, open_img_as_array\n",
    "\n",
    "PATH_TO_DATASET = './CloC/'\n",
    "IMG_SIZE = (217, 334)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [9:16:13<00:00, 333.74s/it] \n"
     ]
    }
   ],
   "source": [
    "with open('results2.txt', 'w') as f:\n",
    "    for path_to_img in tqdm(glob(PATH_TO_DATASET + '*.png')[:100]):\n",
    "        img_name = path_to_img[len(PATH_TO_DATASET):]\n",
    "        f.write(f'{img_name}\\n')\n",
    "        normal_img_array = 1 - open_img_as_array(path_to_img) // 255\n",
    "        steps = [20, 15, 10, 1]\n",
    "        map_cascade = [downscale_map(normal_img_array, step)\n",
    "                       for step in steps]\n",
    "\n",
    "        for i, cas_map in enumerate(map_cascade):\n",
    "            dataset = MyData(path_or_img=255 * cas_map, data_mode='img',\n",
    "                             mode_3d='cylinder', radius=1, reduce_fctor=1, need_info=False)\n",
    "            dataset_list = [dataset]\n",
    "            model = Net(dataset_list=dataset_list, lr=1e-3)\n",
    "            model.to(device)\n",
    "            if i:\n",
    "                model.load_state_dict(torch.load(\n",
    "                    f'./state_dict/GlobalCas/{inum}/{i}_CloC.pt'))\n",
    "            model.start_training(\n",
    "                num_epochs=15e+3, my_weight=0.1, need_plot=False, need_save=False)\n",
    "            inum = img_name.split('.')[0]\n",
    "            model.save_state_dict(\n",
    "                f'./state_dict/GlobalCas/{inum}/{i+1}_CloC.pt')\n",
    "        mse, f1, f2 = model.test_model_(threshold=0.15)\n",
    "        f.write(f'MSE: {mse:.2f} F1: {f1:.2f}, {f2:.2f}\\n\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waclo\\AppData\\Local\\Temp\\ipykernel_16100\\1068870.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'name': name}, ignore_index=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\jupyter_workspace\\_Diploma\\8. Global test.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter_workspace/_Diploma/8.%20Global%20test.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: name}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter_workspace/_Diploma/8.%20Global%20test.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39melif\u001b[39;00m line[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/jupyter_workspace/_Diploma/8.%20Global%20test.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     mse_pretrained, f1_pretrained, f2_pretrained \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mfloat\u001b[39m, f\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39msplit()[\u001b[39m1\u001b[39m:]), \u001b[39mmap\u001b[39m(\u001b[39mfloat\u001b[39m, f\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39msplit()[\u001b[39m1\u001b[39m:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter_workspace/_Diploma/8.%20Global%20test.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m name, [\u001b[39m'\u001b[39m\u001b[39mmse_pretrained\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_pretrained\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf2_pretrained\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m mse_pretrained, f1_pretrained, f2_pretrained\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter_workspace/_Diploma/8.%20Global%20test.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39melif\u001b[39;00m line[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRa\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['name', 'mse_pretrained', 'f1_pretrained', 'f2_pretrained', 'mse_random', 'f1_random', 'f2_random'])\n",
    "with open('results.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        if line[-4:] == '.png':\n",
    "            name = line\n",
    "            df = df.append({'name': name}, ignore_index=True)\n",
    "        elif line[:2] == 'Pr':\n",
    "            mse_pretrained, f1_pretrained, f2_pretrained = map(float, f.readline().split()[1:]), map(float, f.readline().split()[1:])\n",
    "            df.loc[df['name'] == name, ['mse_pretrained', 'f1_pretrained', 'f2_pretrained']] = mse_pretrained, f1_pretrained, f2_pretrained\n",
    "        elif line[:2] == 'Ra':\n",
    "            mse_random, f1_random, f2_random = map(float, f.readline().split()[1:]), map(float, f.readline().split()[1:])\n",
    "            df.loc[df['name'] == name, ['mse_random', 'f1_random', 'f2_random']] = mse_random, f1_random, f2_random\n",
    "\n",
    "df.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "850244c8638196155f69ccd644181272b4a42cc2d794d5c02d6df1253ef9f395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
